#+TITLE: Submit data to GeneNetwork.org

* Table of Contents                                                     :TOC:
 - [[#introduction][Introduction]]
 - [[#immutable-data-and-files][Immutable data and files]]
 - [[#safe-storage][Safe storage]]
 - [[#authorisation][Authorisation]]
 - [[#roles-and-authentication][Roles and authentication]]
 - [[#database-performance-and-caching][Database, performance and caching]]
 - [[#rest-api][REST API]]
 - [[#data-curation][Data curation]]
   - [[#user-level][User level]]
   - [[#curator-level][Curator level]]
   - [[#3rd-party-level][3rd party level]]
 - [[#conclusion][Conclusion]]

* Introduction

GeneNetwork's value is in having all data in one place - this allows
researchers to correlate and compare data between different
experiments using multiple convenient computational methods. Data is
important and it should be *easy* to submit data to the system. The
current data submission process is handled through the [[http://genenetwork.org/][GN1 web
interface]] followed by data curation and acceptance and can be
improved. In this document we discuss the new interface we are
building for GN2.

Critical features of a good upload interface are:

1. Authentication and authorisation
2. Handling of public/non-public data
3. Validation, filtering and curation steps
4. Adding metadata
5. Support reproducible analysis

Initially we'll focus on a REST API so people can upload their data
from R and Python. Later we can also build a browser-based interface.


* Immutable data and files

Data, once accepted in GN2, should be immutable. This is because, once
it exists, we should assume someone will have used it. To guarantee
reproducibility of analysis, we will need to sustain the data in some
way and make it findable. Also, we have to make sure that data is not
overwritten by 'something else'.

This does not mean we can not delete data. But at least, deleting data
should happen in a controlled way with reports and (hopefully)
backups. Ideally, data should be easy to recover. This way we can
address the current issue of reproducible analysis.

File based systems are superior to databases for this purpose. Files
can have unique names and peacefully co-exist on a mixed
mutable/immutable file system. Also synchronizing files is almost
trivial compared to databases containing terabytes of data. Of course
there are tradeofs with performance that should be addressed.

Genotype data is already handled through files.

Phenoype data is stored in a SQL database (except for large files
which are currently in plink binary format). We will move the
phenotype data to files (initially using a hybrid database/file
solution).

* Safe storage

While GN2 files are immutable, users have to be able to upload
data in their own storage areas with their own unique permissions.
GN2 has to be able to find this data and include it in analysis.

Having safe storage (basically directories with specific access
permissions) will allow isolation of data, give privacy and allow
keeping data in escrow (for further validation and processing).

* Authorisation

Once a user is authenticated (see below) the system will find data
using the public data (partly in immutable files, partly in the
database) and by using a file path to the user's safe storage.

We are simplifying authorisation by not having private data in the
public database. This means users can only upload private files to
their designated areas on the server.

* Roles and authentication

The permission system is basically that of authors, groups, curators
and administrators and can be provided by an LDAP-based authentication
system.

Initially gn_server will simply serve users on based on an
authentication token. Later we'll implement a more fine grained
system.

* Database, performance and caching

At this point most phenotype data is stored in the database. The
proposal is to change that to a system where the data is stored in
files. We will keep the database for aggressive caching purposes and
search with the notable stipulation that only public data can be
stored in the database.

* REST API

When all data are stored as files in GN2 it becomes straightforward to
create an upload interface. Basically a REST PUT call can be made to
upload a new file into a user area. Files are named based on their
contents, so no file can be overwritten that has a different
content. Once a genotype/phenotype/meta file exists users should be
able to access them through the REST API.

Initially these files are stored in isolated directories and will not
be public - until a user requests making them public and a curator
(see below) has seen them and moves them to immutable storage.

* Data curation

Curation can happen at three levels. By the (uploading) user, by the
GN curators and by the users of the GN system.

** User level

We create R and Python tools to process the data before uploading into
GN2. This ascertains that the user can check the data (draw plots) and
the data is unified and validated to some extent.

** Curator level

When a user requests making the data public, curators find the data in
the user directories and can run some extra checks on them before and
after adding them to the web services.

** 3rd party level

Other users of GN2 may find fault with entered data. We will create an
online feedback system where users can leave notes related to
individual datasets.

* Conclusion

To deal with data entry a number of critical strategic choices are
proposed:

1. Move to an immutable file-based data store where databases mostly
   act as caches
2. Allow users to upload data only in isolated directories
3. User data is never public
4. Curation happens at three levels and we provide tools for users
   to validate and upload data from R and Python
